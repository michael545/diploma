{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimesFM v1.2.0. See https://github.com/google-research/timesfm/blob/master/README.md for updated APIs.\n",
      "Loaded Jax TimesFM.\n",
      "Loaded PyTorch TimesFM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\code\\finance\\diploma\\myenv-3-10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timesfm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "import numpy as np\n",
    "import os\n",
    "# Import configuration and reusable functions\n",
    "from config_times_fm import TimesFmConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize TimesFm model using configuration\n",
    "tfm = timesfm.TimesFm(\n",
    "    hparams=timesfm.TimesFmHparams(\n",
    "        backend=TimesFmConfig.BACKEND,\n",
    "        per_core_batch_size=TimesFmConfig.PER_CORE_BATCH_SIZE,\n",
    "        horizon_len=TimesFmConfig.HORIZON_LEN,\n",
    "        num_layers=TimesFmConfig.NUM_LAYERS,\n",
    "        model_dims=TimesFmConfig.MODEL_DIMS,\n",
    "        context_len=TimesFmConfig.CONTEXT_LEN\n",
    "    ),\n",
    "    checkpoint=timesfm.TimesFmCheckpoint(huggingface_repo_id=TimesFmConfig.CHECKPOINT_REPO)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reusable plotting function\n",
    "def plot_forecast(actual_data, forecast_data, title, xlabel='Date', ylabel='Price ($)'):\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.plot(actual_data['ds'], actual_data['y'], color='green', label='Actual')\n",
    "    plt.plot(forecast_data['ds'], forecast_data['timesfm'], color='red', linestyle='--', label='Predicted')\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(xlabel, fontsize=10)\n",
    "    plt.ylabel(ylabel, fontsize=10)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(frameon=True, shadow=True)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single dataset\n",
    "def process_dataset(file_path):\n",
    "    # Extract ticker symbol and interval from file name\n",
    "    filename = os.path.basename(file_path)\n",
    "    parts = filename.split('_')\n",
    "    ticker = parts[0]\n",
    "    interval = '1H'  # Default to 1H if not specified\n",
    "    if len(parts) > 1 and parts[1].endswith('.csv'):\n",
    "        interval = parts[1].replace('.csv', '')\n",
    "    \n",
    "    print(f'Processing {ticker} dataset with {interval} interval...')\n",
    "    \n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "    \n",
    "    # Format dataframe for TimesFM\n",
    "    input_df = pd.DataFrame({\n",
    "        'unique_id': [1] * len(df),\n",
    "        'ds': df['Datetime'].values.astype('datetime64[ns]'), \n",
    "        'y': df['Close']\n",
    "    })\n",
    "    \n",
    "    # Config\n",
    "    context_window = 2048\n",
    "    forecast_horizon = 128\n",
    "    max_start = len(input_df) - context_window - forecast_horizon\n",
    "    \n",
    "    if max_start < 0:\n",
    "        print(f'Warning: {ticker} dataset too small for forecasting with current window sizes')\n",
    "        return\n",
    "    \n",
    "    # Define the starting points for each backtesting window\n",
    "    backtest_starts = list(range(0, max_start + 1, forecast_horizon))\n",
    "    \n",
    "    # Create results directory for this ticker if it doesn't exist\n",
    "    ticker_results_dir = os.path.join('results', f'timesfm_{interval}_{ticker}')\n",
    "    os.makedirs(ticker_results_dir, exist_ok=True)\n",
    "    \n",
    "    # Loop through each backtesting window\n",
    "    for idx, start_idx in enumerate(backtest_starts):\n",
    "        print(f'Processing window {idx+1}/{len(backtest_starts)}...')\n",
    "        \n",
    "        context_end = start_idx + context_window\n",
    "        context_data = input_df.iloc[start_idx:context_end]\n",
    "        \n",
    "        forecast_df = tfm.forecast_on_df(\n",
    "            context_data,\n",
    "            freq='h',\n",
    "            value_name='y',\n",
    "            num_jobs=-1\n",
    "        )[:forecast_horizon]\n",
    "        \n",
    "        # Align the forecast with the actual data\n",
    "        actual_start = context_end\n",
    "        actual_end = actual_start + forecast_horizon\n",
    "        actual_data = input_df.iloc[actual_start:actual_end]\n",
    "        forecast_df['ds'] = actual_data['ds'].values\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(actual_data['y'], forecast_df['timesfm'])\n",
    "        mse = mean_squared_error(actual_data['y'], forecast_df['timesfm'])\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # Save results to CSV\n",
    "        results_df = pd.DataFrame({\n",
    "            'date': actual_data['ds'],\n",
    "            'actual': actual_data['y'].values,\n",
    "            'forecast': forecast_df['timesfm'].values\n",
    "        })\n",
    "        csv_path = os.path.join(ticker_results_dir, f'{ticker}_window_{idx+1}.csv')\n",
    "        results_df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        # Plot and save the forecast for this window\n",
    "        plt.figure(figsize=(18, 6))\n",
    "        plt.plot(actual_data['ds'], actual_data['y'], color='green', label='Actual')\n",
    "        plt.plot(forecast_df['ds'], forecast_df['timesfm'], color='red', linestyle='--', marker='o', markersize=3, label='Predicted')\n",
    "        title = f'{ticker} ({interval}) - Window {idx+1} Forecast (MAE: {mae:.4f}, RMSE: {rmse:.4f})'\n",
    "        plt.title(title, fontsize=14)\n",
    "        plt.xlabel('Date', fontsize=10)\n",
    "        plt.ylabel('Price ($)', fontsize=10)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(frameon=True, shadow=True)\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot\n",
    "        plot_path = os.path.join(ticker_results_dir, f'{ticker}_window_{idx+1}.png')\n",
    "        plt.savefig(plot_path, dpi=300)\n",
    "        plt.show()  # Display the plot\n",
    "        \n",
    "        print(f'  MAE: {mae:.4f}, RMSE: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process 1H Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 CSV files in 1H directory:\n",
      "- INTC_1H.csv\n",
      "- IONQ_1H.csv\n",
      "- MSTR_1H.csv\n",
      "- MU_1H.csv\n",
      "- NVDA_1H.csv\n",
      "- QBTS_1H.csv\n",
      "- RGTI_1H.csv\n",
      "- SMCI_1H.csv\n",
      "- SRPT_1H.csv\n",
      "- TSLA_1H.csv\n",
      "- VKTX_1H.csv\n"
     ]
    }
   ],
   "source": [
    "# Define 1H data directory\n",
    "data_dir_1h = os.path.join(os.getcwd(), \"data\", \"1H\")\n",
    "\n",
    "# Get list of all CSV files in the 1H directory\n",
    "csv_files_1h = [os.path.join(data_dir_1h, f) for f in os.listdir(data_dir_1h) if f.endswith('.csv')]\n",
    "\n",
    "if not csv_files_1h:\n",
    "    print(f\"No CSV files found in {data_dir_1h}\")\n",
    "else:\n",
    "    print(f\"Found {len(csv_files_1h)} CSV files in 1H directory:\")\n",
    "    for file in csv_files_1h:\n",
    "        print(f\"- {os.path.basename(file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine all forecasts into single DataFrames\n",
    "# full_forecast = pd.concat(all_forecasts)\n",
    "# full_actual = pd.concat(all_actuals)\n",
    "\n",
    "# Plot the aggregated forecast\n",
    "# plt.figure(figsize=(18, 6))\n",
    "# plt.plot(full_actual['ds'], full_actual['y'], color='#069d12', label='Actual')\n",
    "# plt.plot(full_forecast['ds'], full_forecast['timesfm'], color='#e32227', linestyle='--', label='Predicted')\n",
    "# plt.title('Aggregated Forecast: Actual vs Predicted ($INTC)', fontsize=16)\n",
    "# plt.xlabel('Date', fontsize=12)\n",
    "# plt.ylabel('Price ($)', fontsize=12)\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.legend()\n",
    "# plt.grid(True, linestyle='--', alpha=0.6)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
